{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "import spacy\n",
    "import itertools \n",
    "from math import log\n",
    "from collections import defaultdict\n",
    "\n",
    "class InvertedIndex:\n",
    "    def __init__(self):\n",
    "        ## You should use these variable to store the term frequencies for tokens and entities...\n",
    "        # {key: token/entity, value: {key: doc_id, value: normalised term frequency(token/entity, doc_id)}}\n",
    "        self.tf_tokens = defaultdict(dict)\n",
    "        self.tf_entities = defaultdict(dict)\n",
    "\n",
    "        ## You should use these variable to store the inverse document frequencies for tokens and entities...\n",
    "        # {key: token/entity, value: IDF(token/entity)}\n",
    "        self.idf_tokens = {}\n",
    "        self.idf_entities = {}\n",
    "        \n",
    "        # load the english language model\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # count lemma in description for each candidate entity \n",
    "    def _count_tf_tokens(self, parsed_entity_page):\n",
    "        # tf_count - key: token_lemma, \n",
    "        # value: {key: candidate entity, value: # of this lemma in this entity's description}\n",
    "        token_tf_count = defaultdict(lambda:defaultdict(int))\n",
    "        \n",
    "        for ent in parsed_entity_page:\n",
    "            description = parsed_entity_page[ent]\n",
    "            for _,_,lemma,_,_ in description:\n",
    "                token_tf_count[lemma][ent] += 1\n",
    "        return token_tf_count\n",
    "        \n",
    "    # count term frequencies for entities and tokens in the documents       \n",
    "    def _count_tf(self, documents):\n",
    "        # tf_count - key: term, value: {key: doc_id, value: # of this term in this doc_id}\n",
    "        entity_tf_count = defaultdict(lambda:defaultdict(int))\n",
    "        token_tf_count = defaultdict(lambda:defaultdict(int))\n",
    "\n",
    "        # documents: key - doc_id; value: document_text\n",
    "        for doc_id in documents.keys():\n",
    "            doc_text = self.nlp(documents[doc_id])\n",
    "\n",
    "            # decide to calculate entities first, because single word entities \n",
    "            #should not be counted as tokens, if tokens calculated first, extra deleting\n",
    "            #cost to token list\n",
    "            single_word_entities = defaultdict(list)\n",
    "            \n",
    "            # count tf for entities\n",
    "            for ent in doc_text.ents:\n",
    "                entity_tf_count[ent.text][doc_id] += 1\n",
    "\n",
    "                # if entity is a single word\n",
    "                if len(ent.text.split()) == 1:\n",
    "                    single_word_entities[ent.text].append(ent.start_char)\n",
    "\n",
    "            # count tf for tokens       \n",
    "            for token in doc_text:\n",
    "                if not token.is_stop and not token.is_punct:\n",
    "                    is_single_entity = False\n",
    "                    # ent_iob - 3: begin entity, 2: outside, 1: inside\n",
    "                    if (token.ent_iob == 1 or token.ent_iob == 3) \\\n",
    "                      and token.text in single_word_entities.keys() \\\n",
    "                      and token.idx in single_word_entities[token.text]:\n",
    "                        is_single_entity = True\n",
    "\n",
    "                    if not is_single_entity:\n",
    "                        token_tf_count[token.text][doc_id] += 1\n",
    "                \n",
    "        return entity_tf_count, token_tf_count\n",
    "    \n",
    "    # calculate tf and idf of tokens\n",
    "    def _calc_tf_idf_token(self, token_tf_count, total_doc_no):\n",
    "        for token in token_tf_count.keys():\n",
    "            # calculate tf\n",
    "            for doc_id in token_tf_count[token]:\n",
    "                tf_token = token_tf_count[token][doc_id]\n",
    "                # calculate normalised token tf\n",
    "                self.tf_tokens[token][doc_id] = 1.0 + log(1.0 + log(tf_token))\n",
    "\n",
    "            # calculate token idf\n",
    "            doc_contain_token = len(token_tf_count[token])\n",
    "            self.idf_tokens[token] = 1.0 + log(total_doc_no / (1.0 + doc_contain_token))\n",
    "        return\n",
    "\n",
    "    # calculate tf and idf of entities\n",
    "    def _calc_tf_idf_entity(self, entity_tf_count, total_doc_no):\n",
    "        for ent in entity_tf_count:\n",
    "            # calculate tf\n",
    "            for doc_id in entity_tf_count[ent]:\n",
    "                tf_ent = entity_tf_count[ent][doc_id]\n",
    "\n",
    "                # calculate normalised entity tf\n",
    "                self.tf_entities[ent][doc_id] = 1.0 + log(tf_ent)\n",
    "\n",
    "            # calculate entity idf\n",
    "            doc_contain_ent = len(entity_tf_count[ent])\n",
    "            self.idf_entities[ent] = 1.0 + log(total_doc_no / (1.0 + doc_contain_ent))\n",
    "        return    \n",
    "        \n",
    "    ## Your implementation for indexing the documents...\n",
    "    # add parameter is_dscp: True for input doc is parsed entity description, else normal doc\n",
    "    def index_documents(self, documents, is_dscp):\n",
    "        total_doc_no = len(documents)\n",
    "        \n",
    "        if is_dscp:\n",
    "            token_tf_count = self._count_tf_tokens(documents)\n",
    "            self._calc_tf_idf_token(token_tf_count, total_doc_no)\n",
    "        else:\n",
    "            # get term frequencies\n",
    "            entity_tf_count, token_tf_count = self._count_tf(documents)\n",
    "            \n",
    "            # use tf to calculate normalised tf and idf\n",
    "            self._calc_tf_idf_token(token_tf_count, total_doc_no)\n",
    "            self._calc_tf_idf_entity(entity_tf_count, total_doc_no)\n",
    "\n",
    "\n",
    "    ## Your implementation to return the max score among all the query splits...\n",
    "    # avg_score: if True, get mean tf-idf score, else, get sum \n",
    "    def max_score_query(self, query_splits, doc_id, score_type):\n",
    "        ## Output should be a tuple (max_score, {'tokens': [...], 'entities': [...]})\n",
    "        max_score = 0\n",
    "        max_score_split = {}\n",
    "        for key, split in query_splits.items():\n",
    "            curr_tokens = split['tokens']\n",
    "\n",
    "            score_tokens = []\n",
    "            for token in curr_tokens:\n",
    "                if token in self.tf_tokens.keys() and doc_id in self.tf_tokens[token].keys():\n",
    "                    score_tokens.append(self.tf_tokens[token][doc_id] * self.idf_tokens[token])\n",
    "            \n",
    "            scorei = 0.0 \n",
    "            if len(score_tokens) > 0:\n",
    "                if score_type == 'avg':\n",
    "                    scorei = sum(score_tokens) / len(curr_tokens)\n",
    "                elif score_type == 'sum':\n",
    "                    scorei = sum(score_tokens)\n",
    "                elif score_type == 'max':\n",
    "                    scorei = max(score_tokens)\n",
    "                \n",
    "            \n",
    "            if scorei > max_score:\n",
    "                max_score = scorei\n",
    "                max_score_split = split\n",
    "            \n",
    "        return (max_score, max_score_split)\n",
    "\n",
    "    \n",
    "def get_groups(train_mentions):\n",
    "    # get no. of groups == no. of mentions in train_mentions\n",
    "    n_groups = len(train_mentions)\n",
    "\n",
    "    # get size of each group and store in train_groups\n",
    "    train_groups = np.zeros(n_groups, dtype=int)\n",
    "\n",
    "    # groups is formed in ascending order of key of train_mentions (mention_id)\n",
    "    mention_ids = list(train_mentions.keys())\n",
    "    mention_ids.sort()\n",
    "\n",
    "    idx = 0\n",
    "    for mention_id in mention_ids:\n",
    "        train_groups[idx] = len(train_mentions[mention_id]['candidate_entities'])\n",
    "        idx += 1\n",
    "    return train_groups, mention_ids\n",
    "    \n",
    "# helper Feature: calculate avg tf-idf for each mention\n",
    "def get_mention_tfidf(mention_ids, mentions, doc_index):\n",
    "    mention_tfidf = []\n",
    "    idx = 0\n",
    "    for mention_id in mention_ids:\n",
    "        mention = mentions[mention_id]['mention']\n",
    "        doc_title = mentions[mention_id]['doc_title']\n",
    "        no_candidates = len(mentions[mention_id]['candidate_entities'])\n",
    "\n",
    "        # split mention to tokens\n",
    "        split = {1: {'entities': [], 'tokens': mention.split()}}\n",
    "        score, _ = doc_index.max_score_query(split, doc_title, 'avg')\n",
    "        \n",
    "        mention_tfidf += no_candidates * [score]\n",
    "        \n",
    "    return mention_tfidf\n",
    "\n",
    "# feature: calculate avg tf-idf for each candidate entity\n",
    "def get_candidate_ent_tfidf(mention_ids, mentions, doc_index):\n",
    "    ent_tfidf = []\n",
    "    for mention_id in mention_ids:\n",
    "        doc_title = mentions[mention_id]['doc_title']\n",
    "        c_ents = mentions[mention_id]['candidate_entities']\n",
    "        for ent in c_ents:\n",
    "            split = {1: {'entities': [], 'tokens': ent.split('_')}}\n",
    "            score, _ = doc_index.max_score_query(split, doc_title, 'avg')\n",
    "            \n",
    "            ent_tfidf.append(score)\n",
    "    return ent_tfidf\n",
    "\n",
    "# feature: get candidate entity description tfidf\n",
    "def get_ent_dscp_tfidf(mention_ids, mentions, parsed_entity_pages, doc_index):\n",
    "    ent_dscp_tfidf = []\n",
    "    for mention_id in mention_ids:\n",
    "        doc_title = mentions[mention_id]['doc_title']\n",
    "        c_ents = mentions[mention_id]['candidate_entities']\n",
    "        for ent in c_ents:\n",
    "            dscp = parsed_entity_pages[ent]\n",
    "            dlemmas = [lemma for _,_,lemma,_,_ in dscp]\n",
    "            split = {1: {'entities': [], 'tokens': dlemmas}}\n",
    "            score, _ = doc_index.max_score_query(split, doc_title, 'avg')\n",
    "            \n",
    "            ent_dscp_tfidf.append(score)\n",
    "    return ent_dscp_tfidf\n",
    "\n",
    "# feature: mention and ent exactly match or not\n",
    "def get_mention_ent_match(mention_ids, mentions):\n",
    "    mention_ent_match = []\n",
    "    for mention_id in mention_ids:\n",
    "        mention = mentions[mention_id]['mention']\n",
    "        mtokens = [mt.lower() for mt in mention.split()]\n",
    "        \n",
    "        c_ents = mentions[mention_id]['candidate_entities']\n",
    "        for ent in c_ents:\n",
    "            etokens = [et.lower() for et in ent.split('_')]\n",
    "            mention_ent_match.append(mtokens == etokens)\n",
    "\n",
    "    return mention_ent_match\n",
    "\n",
    "# feature: F1 score for mention in candidate entity description\n",
    "def get_mention_dscp_f1(mention_ids, mentions, parsed_entity_pages):\n",
    "    mention_ent_f1 = []\n",
    "    for mention_id in mention_ids:\n",
    "        mention = mentions[mention_id]['mention']\n",
    "        mtokens = [mt.lower() for mt in mention.split()]\n",
    "        \n",
    "        c_ents = mentions[mention_id]['candidate_entities']\n",
    "        for ent in c_ents:\n",
    "            dscp = parsed_entity_pages[ent]\n",
    "            dscp_tokens = [t.lower() for _,t,_,_,_ in dscp]\n",
    "            \n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            F1 = 0\n",
    "            if len(dscp_tokens) > 0 and len(mtokens) > 0:\n",
    "                # true positive: # mention token match in entity token\n",
    "                dscp_TP = len([dt for dt in dscp_tokens if dt in mtokens])\n",
    "                mention_TP = len([mt for mt in mtokens if mt in dscp_tokens])\n",
    "                \n",
    "                precision = dscp_TP / len(dscp_tokens)\n",
    "                recall = mention_TP / len(mtokens)\n",
    "                if precision + recall > 0:\n",
    "                    F1 = (2 * precision * recall) / (precision + recall)\n",
    "            \n",
    "            mention_ent_f1.append(F1)        \n",
    "    return mention_ent_f1\n",
    "\n",
    "# feature: mention tokens in description \n",
    "def get_mention_dscp_tfidf(mention_ids, mentions, parsed_entity_pages):\n",
    "    mention_dscp_tfidf = []\n",
    "    mention_dscp_tfidf_max = []\n",
    "    # build inverted index for dscp\n",
    "    # calculate tf and idf for all terms in description\n",
    "    dscp_index = InvertedIndex()\n",
    "    dscp_index.index_documents(parsed_entity_pages, True)\n",
    "    \n",
    "    for mention_id in mention_ids:\n",
    "        mention = mentions[mention_id]['mention']\n",
    "        ents = mentions[mention_id]['candidate_entities']\n",
    "        \n",
    "        for ent in ents:\n",
    "            #split = {1: {'entities': ments, 'tokens': mtokens}}\n",
    "            split = {1: {'entities': [], 'tokens': mention.split()}}\n",
    "\n",
    "            score,_ = dscp_index.max_score_query(split, ent, 'avg')\n",
    "            mention_dscp_tfidf.append(score)\n",
    "            score,_ = dscp_index.max_score_query(split, ent, 'max')\n",
    "            mention_dscp_tfidf_max.append(score)\n",
    "            \n",
    "    return [mention_dscp_tfidf, mention_dscp_tfidf_max]\n",
    "\n",
    "# feature: mention entity name pos match\n",
    "def get_mention_ent_postag_match(mention_ids, mentions, doc_index):\n",
    "    mention_ent_postag_match = []\n",
    "    \n",
    "    for mention_id in mention_ids:\n",
    "        mention = mentions[mention_id]['mention']\n",
    "        parsed_mention = doc_index.nlp(mention)\n",
    "        mpos = [mtoken.pos_ for mtoken in parsed_mention]\n",
    "        mentlabel = [ment.label_ for ment in parsed_mention.ents]\n",
    "            \n",
    "        ents = mentions[mention_id]['candidate_entities']\n",
    "        for ent in ents:\n",
    "            parsed_ent = doc_index.nlp(ent)\n",
    "            epos = [etoken.pos_ for etoken in parsed_ent]\n",
    "            mention_ent_postag_match.append(mpos == epos)\n",
    "    \n",
    "    return mention_ent_postag_match\n",
    "\n",
    "# local paragraph\n",
    "def get_local_doc(men_docs, mentions, mention_ids):\n",
    "    local_doc = defaultdict(str)\n",
    "    for mention_id in mention_ids:\n",
    "        doc_title = mentions[mention_id]['doc_title']\n",
    "        offset = mentions[mention_id]['offset']\n",
    "        length = mentions[mention_id]['length']\n",
    "        doc = men_docs[doc_title]\n",
    "        \n",
    "        # get start and end index of local sentence\n",
    "        start_idx = 0\n",
    "        for curr_idx in range(offset, 1, -1):\n",
    "            if doc[curr_idx-1] == '\\n':\n",
    "                start_idx = curr_idx\n",
    "                break\n",
    "            \n",
    "        end_idx = len(doc)-1\n",
    "        for curr_idx in range(offset + length, len(doc)-1, 1):\n",
    "            if doc[curr_idx+1] == '\\n':\n",
    "                end_idx = curr_idx + 1\n",
    "                break\n",
    "\n",
    "        local_doc[doc_title] += doc[start_idx:end_idx] + '\\n'\n",
    "    return local_doc\n",
    "\n",
    "def get_doc_features(mention_ids, mentions, parsed_entity_pages, doc_index, groups):\n",
    "    mention_tfidf = get_mention_tfidf(mention_ids, mentions, doc_index)\n",
    "    ent_tfidf = get_candidate_ent_tfidf(mention_ids, mentions, doc_index)\n",
    "    ent_dscp_tfidf = get_ent_dscp_tfidf(mention_ids, mentions, parsed_entity_pages, doc_index)\n",
    "    \n",
    "    # diff in mention tfidf and candidate entity name tfidf\n",
    "    me_diff = np.array(mention_tfidf) - np.array(ent_tfidf)\n",
    "    \n",
    "    return [me_diff, ent_tfidf, ent_dscp_tfidf]\n",
    "    \n",
    "def get_features(mention_ids, mentions, parsed_entity_pages, doc_index, \n",
    "                 local_doc_index, groups, docs):\n",
    "    n_row = 9\n",
    "    n_col = sum(groups)\n",
    "    features = np.zeros((n_row, n_col), dtype=float)\n",
    "    \n",
    "    # feature: if mention and entity exactly match each other\n",
    "    mention_ent_match = get_mention_ent_match(mention_ids, mentions)\n",
    "    # feature: tfidf of mention tokens in candidate entity descriptions\n",
    "    mention_dscp_tfidf, mention_dscp_tfidf_max = get_mention_dscp_tfidf(mention_ids, mentions, parsed_entity_pages)\n",
    "    mention_dscp_f1 = get_mention_dscp_f1(mention_ids, mentions, parsed_entity_pages)\n",
    "    \n",
    "    featurelist = get_doc_features(mention_ids, mentions, parsed_entity_pages, \n",
    "                                            doc_index, groups)\n",
    "    featurelist.append(get_ent_dscp_tfidf(mention_ids, mentions, parsed_entity_pages, \n",
    "                                          local_doc_index))\n",
    "    \n",
    "    featurelist += [mention_ent_match, np.array(mention_dscp_tfidf), mention_dscp_f1]\n",
    "    \n",
    "    # new feature\n",
    "    mention_ent_postag_match = get_mention_ent_postag_match(mention_ids, mentions, doc_index)\n",
    "    featurelist.append(mention_ent_postag_match)\n",
    "    \n",
    "    featurelist.append(mention_dscp_tfidf_max)\n",
    "    \n",
    "    for i in range(n_row):\n",
    "        features[i] = featurelist[i]\n",
    "    \n",
    "    features = features.transpose()\n",
    "    return features    \n",
    "    \n",
    "def get_xgb_train_labels(train_labels, mention_ids, train_mentions):\n",
    "    xgb_train_labels = []\n",
    "    for mention_id in mention_ids:\n",
    "        select_ent = train_labels[mention_id]['label']\n",
    "        ents = train_mentions[mention_id]['candidate_entities']\n",
    "        for ent in ents:\n",
    "            xgb_train_labels.append(ent == select_ent)\n",
    "            \n",
    "    return xgb_train_labels\n",
    "\n",
    "# transform training features, groups, labels to xgboost input form\n",
    "def transform_data(features, groups, labels=None):\n",
    "    xgb_data = xgb.DMatrix(data=features, label=labels)\n",
    "    xgb_data.set_group(groups)\n",
    "    return xgb_data\n",
    "\n",
    "def get_result(preds, dev_mentions, test_groups):\n",
    "    idx = 0\n",
    "    result = {}\n",
    "    for iter_, group in enumerate(test_groups):\n",
    "        mention_id = iter_ + 1\n",
    "        group_result = preds[idx:idx+group]\n",
    "        max_score = max(group_result)\n",
    "        local_idx = np.where(group_result == max_score)[0][0]\n",
    "\n",
    "        highest_score_ent = dev_mentions[mention_id]['candidate_entities'][local_idx]\n",
    "        result[mention_id] = highest_score_ent\n",
    "        idx+=group\n",
    "    return result\n",
    "\n",
    "def disambiguate_mentions(train_mentions, train_labels, dev_mentions, men_docs, parsed_entity_pages):\n",
    "    train_groups, mention_ids = get_groups(train_mentions)\n",
    "    \n",
    "    # calculate tf and idf for all terms in men_doc\n",
    "    doc_index = InvertedIndex()\n",
    "    doc_index.index_documents(men_docs, False)\n",
    "\n",
    "    # choose local_doc or men_docs\n",
    "    local_doc_index = InvertedIndex()\n",
    "    local_doc = get_local_doc(men_docs, train_mentions, mention_ids)\n",
    "    local_doc_index.index_documents(local_doc, False)\n",
    "    \n",
    "    # get training data\n",
    "    train_features = get_features(mention_ids, train_mentions, parsed_entity_pages,\n",
    "                                  doc_index, local_doc_index, train_groups, men_docs)\n",
    "    xgb_train_labels = get_xgb_train_labels(train_labels, mention_ids, train_mentions)\n",
    "    xgboost_train = transform_data(train_features, train_groups, xgb_train_labels)\n",
    "    \n",
    "    \n",
    "    # get testing data\n",
    "    test_groups, test_mention_ids = get_groups(dev_mentions)\n",
    "    test_features = get_features(test_mention_ids, dev_mentions, parsed_entity_pages, \n",
    "                                 doc_index,local_doc_index, test_groups, men_docs)\n",
    "    xgboost_test = transform_data(test_features, test_groups)\n",
    "    \n",
    "    \n",
    "    # train model\n",
    "    param = {'max_depth': 8, 'eta': 0.05, 'silent': 1, 'objective': 'rank:pairwise',\n",
    "         'min_child_weight': 0.01, 'lambda':100, 'subsample':0.8}\n",
    "\n",
    "    ## Train the classifier...\n",
    "    classifier = xgb.train(param, xgboost_train, num_boost_round=4900)\n",
    "    ##  Predict test data...\n",
    "    preds = classifier.predict(xgboost_test)\n",
    "    \n",
    "    result = get_result(preds, dev_mentions, test_groups)\n",
    "    return result, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will be using the following function to compute the accuracy...\n",
    "def compute_accuracy(result, data_labels):\n",
    "    assert set(list(result.keys())) - set(list(data_labels.keys())) == set()\n",
    "    TP = 0.0\n",
    "    for id_ in result.keys():\n",
    "        if result[id_] == data_labels[id_]['label']:\n",
    "            TP +=1\n",
    "    assert len(result) == len(data_labels)\n",
    "    return TP/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the data sets...\n",
    "import pickle\n",
    "### Read the Training Data\n",
    "train_file = './Data/train.pickle'\n",
    "train_mentions = pickle.load(open(train_file, 'rb'))\n",
    "\n",
    "### Read the Training Labels...\n",
    "train_label_file = './Data/train_labels.pickle'\n",
    "train_labels = pickle.load(open(train_label_file, 'rb'))\n",
    "\n",
    "### Read the Dev Data... (For Final Evaluation, we will replace it with the Test Data)\n",
    "dev_file = './Data/dev.pickle'\n",
    "dev_mentions = pickle.load(open(dev_file, 'rb'))\n",
    "\n",
    "### Read the Parsed Entity Candidate Pages...\n",
    "fname = './Data/parsed_candidate_entities.pickle'\n",
    "parsed_entity_pages = pickle.load(open(fname, 'rb'))\n",
    "\n",
    "### Read the Mention docs...\n",
    "mens_docs_file = \"./Data/men_docs.pickle\"\n",
    "men_docs = pickle.load(open(mens_docs_file, 'rb'))\n",
    "\n",
    "### Read the Dev Labels... (For Final Evaluation, we will replace it with the Test Data)\n",
    "dev_label_file = './Data/dev_labels.pickle'\n",
    "dev_labels = pickle.load(open(dev_label_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load from dev 2 folder\n",
    "# train_mentions and train_labels are same\n",
    "\n",
    "### Read the Parsed Entity Candidate Pages...\n",
    "fname2 = './Dev_set_2/parsed_candidate_entities.pickle'\n",
    "parsed_entity_pages2 = pickle.load(open(fname2, 'rb'))\n",
    "\n",
    "### Read the Mention docs...\n",
    "mens_docs_file2 = \"./Dev_set_2/men_docs.pickle\"\n",
    "men_docs2 = pickle.load(open(mens_docs_file2, 'rb'))\n",
    "\n",
    "# load 2nd test data and label\n",
    "dev_mentions_file2 = './Dev_set_2/dev2.pickle'\n",
    "dev_mentions2 = pickle.load(open(dev_mentions_file2, 'rb'))\n",
    "\n",
    "### Read the Dev Labels... (For Final Evaluation, we will replace it with the Test Data)\n",
    "dev_label_file2 = './Dev_set_2/dev2_labels.pickle'\n",
    "dev_labels2 = pickle.load(open(dev_label_file2, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance using built-in function\n",
    "%matplotlib inline\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  125.78975105285645\n"
     ]
    }
   ],
   "source": [
    "## Result of the model...\n",
    "t1 = time.time()\n",
    "result,classifier = disambiguate_mentions(train_mentions, train_labels, dev_mentions2,\n",
    "                                             men_docs2, parsed_entity_pages2)\n",
    "print('time taken: ', time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Dev 2 =  0.7577639751552795\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Read the Dev Labels... (For Final Evaluation, we will replace it with the Test Data)\n",
    "\n",
    "accuracy = compute_accuracy(result, dev_labels2)\n",
    "print(\"Accuracy Dev 2 = \", accuracy)\n",
    "plot_importance(classifier)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-a82302bbb0b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m result,classifier = disambiguate_mentions(train_mentions, train_labels, dev_mentions, \n\u001b[0;32m----> 4\u001b[0;31m                                              men_docs, parsed_entity_pages)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time taken: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-e2f37c89344b>\u001b[0m in \u001b[0;36mdisambiguate_mentions\u001b[0;34m(train_mentions, train_labels, dev_mentions, men_docs, parsed_entity_pages)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;31m# get training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     train_features = get_features(mention_ids, train_mentions, parsed_entity_pages,\n\u001b[0;32m--> 407\u001b[0;31m                                   doc_index, local_doc_index, train_groups, men_docs)\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0mxgb_train_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_xgb_train_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmention_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mxgboost_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_train_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-e2f37c89344b>\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(mention_ids, mentions, parsed_entity_pages, doc_index, local_doc_index, groups, docs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;31m# new feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mmention_ent_postag_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mention_ent_postag_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmention_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mfeaturelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmention_ent_postag_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-e2f37c89344b>\u001b[0m in \u001b[0;36mget_mention_ent_postag_match\u001b[0;34m(mention_ids, mentions, doc_index)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0ments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmentions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmention_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'candidate_entities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mparsed_ent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0mepos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0metoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0metoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparsed_ent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mmention_ent_postag_match\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mepos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserModel.begin_update\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(seqs_in, drop)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/thinc/neural/_classes/resnet.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/thinc/neural/_classes/convolution.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X__bi, drop)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX__bi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mX__bo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq2col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX__bi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mfinish_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_finish_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX__bo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Result of the model...\n",
    "t1 = time.time()\n",
    "result,classifier = disambiguate_mentions(train_mentions, train_labels, dev_mentions, \n",
    "                                             men_docs, parsed_entity_pages)\n",
    "print('time taken: ', time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the Dev Labels... (For Final Evaluation, we will replace it with the Test Data)\n",
    "\n",
    "accuracy = compute_accuracy(result, dev_labels)\n",
    "print(\"Accuracy Dev= \", accuracy)\n",
    "plot_importance(classifier)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
