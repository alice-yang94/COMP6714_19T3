{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadline + Late Penalty\n",
    "\n",
    "$\\textbf{Note:}$ It will take you quite some time to complete this project, therefore, we earnestly recommend that you start working as early as possible. You should read the specs carefully at least 2-3 times before you start coding.\n",
    "\n",
    "* $\\textbf{Submission deadline for the Project (Part-1) is 20:59:59 (08:59:59 PM) on 4th Nov, 2019}$\n",
    "* $\\textbf{LATE PENALTY: 10% on day-1 and 20% on each subsequent day.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. This note book contains instructions for $\\textbf{COMP6714-Project (Part-1)}$. We will release the instructions for the $\\textbf{Part-2 of the Project}$ in a seperate notebook. \n",
    "\n",
    "* You are required to complete your implementation for part-1 in a file `project_part1.py` provided along with this notebook. Please $\\textbf{DO NOT ALTER}$ the name of the file.\n",
    "\n",
    "* You are not allowed to print out unnecessary stuff. We will not consider any output printed out on the screen. All results should be returned in appropriate data structures via corresponding functions.\n",
    "\n",
    "* You can submit your implementation for **Project (Part-1)** via submission system: http://kg.cse.unsw.edu.au/submit/ . We have already sent out the invitations for you to join the submission system. In case of problems please post your request @ Piazza.\n",
    "\n",
    "* For each question, we have provided you with detailed instructions along with question headings. In case of problems, you can post your query @ Piazza.\n",
    "\n",
    "* You are allowed to add other functions and/or import modules (you may have to for this project), but you are not allowed to define global variables. **Only functions are allowed** in `project_part1.py`\n",
    "\n",
    "* You should not import unnecessary and non-standard modules/libraries. Loading such libraries at test time will lead to errors and hence 0 mark for your project. If you are not sure, please ask @ Piazza. \n",
    "\n",
    "* We will provide immediate feedback on your submission. You can access your scores using the online submission portal on the same day. \n",
    "\n",
    "* For the **Final Evaluation**, we will be using a different dataset, so your final scores may vary.  \n",
    "\n",
    "* You are allowed to have a limited number of Feedback Attempts $\\textbf{(15 Attempts for each student)}$, we will use your **LAST** submission for Final Evaluation.\n",
    "\n",
    "### Allowed Libraries:\n",
    "\n",
    "You are required to write your implementation for the project (part-1) using `Python 3.6.5`. You are only allowed to use the following python libraries:\n",
    "* $\\textbf{spacy (v2.1.8)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Compute TF-IDF score for query (80 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this project, you are required to compute $TF\\text{-}IDF$ score of a document $D_{j}$ $\\textit{w.r.t}$ an input query $Q$ and a Dictionary of Entities $(DoE)$.\n",
    "\n",
    "### Inputs (Q1):\n",
    "Inputs to your model are as follows:\n",
    "1. Documents ($D$) as a dictionary with $key:$ doc_id; $value:$ document text\n",
    "* Query ($Q$), as a string of words\n",
    "* Dictionary of Entities ($DoE$), with $key:$ entity; $value:$ entity_id\n",
    "\n",
    "The procedure for computation of the $TF\\text{-}IDF$ score follows following steps:\n",
    "\n",
    "1. $\\textbf{TF-IDF index construction for Entities and Tokens}$\n",
    "* $\\textbf{Split the query into lists of Entities and Tokens}$\n",
    "* $\\textbf{Query Score Computation}$\n",
    "\n",
    "Detailed description of these steps is as under:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TF-IDF index construction for Entities and Tokens\n",
    "\n",
    "We require you to separately learn TF-IDF index for tokens ($TF\\text{-}IDF_{token}$) and entities ($TF\\text{-}IDF_{entity}$). The computation of each of the TF-IDF index is given as follows: \n",
    "\n",
    "### TF-IDF index For Tokens:\n",
    "\n",
    "The term frequency of the token $t$ in a document $D_{j}$ is computed as follows:\n",
    "\n",
    "$$\n",
    "TF_{token}(t,D_{j}) = {\\# \\; of \\; times \\; token \\; t \\; appears \\; in \\; D_{j}}\n",
    "$$\n",
    "\n",
    "\n",
    "To de-emphasize the high token frequency, we apply double log to normalize the term frequency. The computation of normalized term frequency of token $t$ is illustrated as follows:\n",
    "\n",
    "$$\n",
    "TF_{norm\\_token}(t,D_{j}) =  1.0 + \\ln(1.0 + \\ln(TF_{token}(t,D_{j})))\n",
    "$$\n",
    "\n",
    "And, the Inverse Document Frequency of the token $t$ is computed as follows: \n",
    "\n",
    "$$\n",
    "IDF_{token}(t) = 1.0 + \\ln(\\frac{total \\; \\# \\; of \\; docs}{1.0 + \\# \\; of \\; docs \\; containing \\; token \\; \\textit{t}})\n",
    "$$\n",
    "\n",
    "The TF-IDF score of token $t$ in document $D_{j}$ is computed as: <br>\n",
    "\n",
    "$$\n",
    "TF\\text{-}IDF_{token}(t,D_{j}) = TF_{norm\\_token}(t,D_{j}) * IDF_{token}(t)\n",
    "$$\n",
    "\n",
    "\n",
    "### TF-IDF index for Entities:\n",
    "The term frequency of the entity $e$ in a document $D_{j}$ is computed as follows:\n",
    "\n",
    "$$\n",
    "TF_{entity}(e,D_{j}) = {\\# \\; of \\; times \\; entity \\; e \\; appears \\; in \\; D_{j}}\n",
    "$$\n",
    "\n",
    "We simply use natural log to normalize the term frequency of the entities, as given below:\n",
    "\n",
    "$$\n",
    "TF_{norm\\_entity}(e,D_{j}) =  1.0 + \\ln(TF_{entity}(e,D_{j}))\n",
    "$$\n",
    "\n",
    "And, the Inverse Document Frequency of the entity $e$ is computed as follows: \n",
    "\n",
    "\n",
    "$$\n",
    "IDF_{entity}(e) = 1.0 + \\ln(\\frac{total \\; \\# \\; of \\; docs}{1.0 + \\# \\; of \\; docs \\; containing \\; entity \\; \\textit{e}})\n",
    "$$\n",
    "\n",
    "\n",
    "The TF-IDF score of the entity $e$ in the document $D_{j}$ is computed as: <br>\n",
    "\n",
    "$$\n",
    "TF\\text{-}IDF_{entity}(e,D_{j}) = TF_{norm\\_entity}(e,D_{j}) * IDF_{entity}(e)\n",
    "$$\n",
    "\n",
    "$\\textbf{Note:}$ We assign `TF-IDF score = 0.0` for the cases where the term frequency (TF) for the token and/or entity is `ZERO`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the Query into Entities and Tokens:\n",
    "\n",
    "At first, you are required to split the query ($Q$) into all possible combinations of free keywords, i.e., tokens ($K = \\{k_{i}\\}_{i=1}^{N}$) and entities ($E= \\{e_{i}\\}_{i=1}^{N}$), where entities correspond to a subset of entities found in $DoE$ formed by individual and/or combination of tokens in $Q$. This process is explained below:\n",
    "\n",
    "> $\\textbf{Step 1:}$ We look for probable entities in the $Q$ by considering individual and/or combination of query tokens formed by combining the tokens in the increasing order of the query string. Amongst them, we only select the entities present in $DoE$.<br>\n",
    "> $\\textbf{Step 2:}$ Based on the selected list of entities found in $\\textbf{Step-1}$ enumerate all possible subsets of entities.<br>\n",
    "> $\\textbf{Step 3:}$ Filter subsets of entities found in $\\textbf{Step-2}$ such that for each subset the token count does not exceed the corresponding token count in $Q$. We treat the filtered subset as the final entities of the corresponding query split.<br>\n",
    "> $\\textbf{Step 4:}$ For each filtered entity subset, the rest of the keywords in the query, i.e., $(Q \\setminus wordsInEntities(e_{i}))$ are treated as the tokens of the query split.<br>\n",
    "\n",
    "\n",
    "Formally, let query be a a string of tokens, e.g., $Q = \\;\"A\\;B \\;C \\;D \\;E \\;F\\; G\"$ and dictionary of entities be $DoE = \\{AB, DF, GK\\}$. The list of entities formed by the tokens in the query and/or combinations of query tokens (contained in $DoE$) is $[AB, DF]$ and upon enumerating the possible subsets of the entities, we get following different possible splits of the query to the lists of the entities and the tokens:\n",
    "\n",
    "$\\textbf{Split-1:}$ $e_{1} = []$; $k_{1} = [A,B,C,D,E,F,G]$\n",
    "\n",
    "$\\textbf{Split-2:}$ $e_{2} = [AB]$; $k_{2} = [C,D,E,F,G]$\n",
    "\n",
    "$\\textbf{Split-3:}$ $e_{3} = [DF]$; $k_{3} = [A,B,C,E,G]$\n",
    "\n",
    "$\\textbf{Split-4:}$ $e_{4} = [AB, DF ]$; $k_{4} = [C,E,G]$\n",
    "\n",
    "$\\textbf{Note:}$ <br>\n",
    "1. In order to split the query, we only care about the subset of entities contained in $DoE$ that can be formed by individual and/or combination of tokens in the $Q$.\n",
    "\n",
    "* Entities in $DoE$ may correspond to single and/or multiple tokens, e.g., in the example given above $A$, $ABC$ etc., may also correspond to valid entities and may appear in the $DoE$.\n",
    "\n",
    "* Maximum number of query splits are upper-bounded by the subset of the entities in $DoE$ that can be formed by the tokens in the $Q$.\n",
    "\n",
    "* For every query split, the leftover keywords $Q \\setminus wordsInEntities(e_{i})$ are considered as the corresponding token split.\n",
    "\n",
    "* In order to form entities, we only combine keywords in the increasing order of the elements in the query string. For example, in $Q =\\; \"A\\; B\\; C\\; D\\; E\\; F\\; G\\;\"$, the entities such as: $BA$, $CB$ etc., will not be considered as entities and hence will not appear in the $DoE$.\n",
    "\n",
    "* In the example given above, if $DoE$ = $\\{AB, BC\\}$, then there will be only three possible splits of the query. Because the $Q$ contains only one instance of the token $B$, so it will not be possible to form a subset with multiple entities $[AB, BC]$, as it would require at least two instances of token $B$ in the $Q$ (also discussed in $\\textbf{Step-3}$ above )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Score Computation:\n",
    "\n",
    "Later, you are required to use the corresponding $TF\\text{-}IDF$ index to separately compute scores for the list of tokens and entities corresponding to each query split, i.e., $(k_{i},e_{i})$, $\\textit{w.r.t}$ the document $D_{j}$ as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "s_{i1} = \\sum_{entity \\in e_{i}} TF_{norm\\_entity}(entity,D_{j}) * IDF_{entity}(entity) \\\\\n",
    "s_{i2} = \\sum_{token \\in k_{i}} TF_{norm\\_token}(token,D_{j}) * IDF_{token}(token) \\\\\n",
    "score_{i}(\\{k_{i},e_{i}\\}, D_{j}) = s_{i1} + \\lambda * s_{i2}|_{\\lambda = 0.4}\n",
    "$$\n",
    "\n",
    "Finally, you are required to return the maximum score among all the query splits, i.e.,\n",
    "\n",
    "$$\n",
    "score_{max} = max\\{score_{i}\\}_{i=1}^{N}\\\\\n",
    "$$\n",
    "\n",
    "Note, in the above-mentioned equations, we use two separate $TF\\text{-}IDF$ indexes, i.e., ($TF\\text{-}IDF_{token}$) and ($TF\\text{-}IDF_{entity}$) to compute the scores for the token splits and the entity splits of the query respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some key instructions regarding TF-IDF indexing, parsing and text processing are as follows:\n",
    "\n",
    "### Key Instructions:\n",
    "\n",
    "1. **Note** that for a given set of documents, you only need to index the documents only once and later use your index to compute the query scores.\n",
    "\n",
    "* You are only allowed to use Spacy (v2.1.8) for text processing and parsing. You can install the Spacy via following web-link: [Spacy](https://spacy.io/usage)\n",
    "\n",
    "* We assume the parsing result of Spacy is always correct, we will not cater to any in-consistency in the Spacy's parsing results. \n",
    "\n",
    "* All the tokens in the documents $(D)$, query $(Q)$ and dictionary of entities $(DoE)$ are case-sensitive. You  $\\textbf{SHOULD NOT ALTER}$ the case of the tokens.\n",
    "\n",
    "* You are required to compute two separate indexes, i.e., (i) For tokens, and (ii) For Entities, such that:\n",
    "\n",
    "> 1. In order to compute the index of the Entities (i.e., $TF\\text{-}IDF_{entity}$), you should index all the entities detected by spacy irrespective of their entity types and/or presence in $DoE$. For details on spacy's parsing and entity recognition, please see the web-link: [Spacy Parsing](https://spacy.io/usage/linguistic-features)<br>\n",
    "> 2. For single-word Entities, e.g., `Trump` etc., you should only compute the index corresponding to the entities. For such entities, you should not consider the corresponding token for computing the TF-IDF index of tokens.<br>\n",
    "> 3. For multi-word entities, e.g., `New York Times` etc., individual tokens corresponding to the entities should be considered as free tokens and should be indexed while TF-IDF index construction of tokens (i.e., $TF\\text{-}IDF_{token}$).<br>\n",
    "\n",
    "* `Stopwords`: You should only use the token's attribute `is_stop` on a string parsed by Spacy to declare any token as stopword and eventually remove it. This also applies to stopwords within multi-word entities, e.g., `Times of India`.\n",
    "\n",
    "* `Punctuation`: You should only use the token's attribute `is_punct` on a string parsed by Spacy to decalre any token as a punctuation mark and eventually remove it.\n",
    "\n",
    "* `Special Cases`: You should not explicitly strip out punctuations or amend the Spacy's tokenization and parsing results. Some examples in this regard are as follows:\n",
    "> 1. In the sentence: `I am going to U.S.` the correctly extracted entity is `U.S.`<br>\n",
    "  2. Likewise, in the sentence: `I am going to school.` the spacy will extract the token `school` and will consider the fullstop `.`  as a punctuation mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example for Illustration\n",
    "\n",
    "Here, we provide a small toy example for illustration: <br>\n",
    "Let the dictionary of documents ($D$) be:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "documents = {1:'President Trump was on his way to new New York in New York City.',\n",
    "             2:'New York Times mentioned an interesting story about Trump.',\n",
    "             3:'I think it would be great if I can travel to New York this summer to see Trump.'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term frequencies corresponding to the tokens (i.e., $TF_{token}$) are shown below as a dictionary of dictionary of the form: <br> \n",
    "$\\{token$ : $\\{doc\\_id: count\\}\\}$."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'President': {1: 1},\n",
    " 'way': {1: 1},\n",
    " 'new': {1: 1},\n",
    " 'New': {1: 2, 2: 1, 3: 1},\n",
    " 'York': {1: 2, 2: 1, 3: 1},\n",
    " 'City': {1: 1},\n",
    " 'Times': {2: 1},\n",
    " 'mentioned': {2: 1},\n",
    " 'interesting': {2: 1},\n",
    " 'story': {2: 1},\n",
    " 'think': {3: 1},\n",
    " 'great': {3: 1},\n",
    " 'travel': {3: 1},\n",
    " 'summer': {3: 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, The term frequencies corresponding to the entities (i.e., $TF_{entity}$) are shown below as a dictionary of dictionary of the form: <br> \n",
    "$\\{entity$ : $\\{doc\\_id: count\\}\\}$."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'Trump': {1: 1, 2: 1, 3: 1},\n",
    " 'New York': {1: 1, 3: 1},\n",
    " 'New York City': {1: 1},\n",
    " 'New York Times': {2: 1},\n",
    " 'this summer': {3: 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the query ($Q$) be:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q = 'New York Times Trump travel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the $DoE$ be:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DoE = {'New York Times':0, 'New York':1,'New York City':2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible query splits are:\n",
    "\n",
    "$e_1$ = [], $k_1$ =  [`New`, `York`, `Times`, `Trump`, `travel`]\n",
    "\n",
    "$e_2$ = [`New York Times`], $k_2$ = [`Trump`, `travel`]\n",
    "\n",
    "$e_3$ = [`New York`], $k_3$= [`Times`, `Trump`, `travel`]\n",
    "\n",
    "$\\textbf{Note:}$ We cannot select the query split with the entity part as the combination of following entities: $e_{i}$ = [`New York`, `New York Times`], because there are only single instances of the tokens `New` and `York` in the $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `doc_id=3`, after applying the formulas mentioned in sub-headings `2,3` given above, we get following scores for all the query splits:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "query =  {'tokens': ['New', 'York', 'Times', 'Trump', 'travel'], 'entities': []}\n",
    "{'tokens_score': 2.8301009632046026, 'entities_score': 0.0, 'combined_score': 1.132040385281841}\n",
    "\n",
    "query =  {'tokens': ['Trump', 'travel'], 'entities': ['New York Times']}\n",
    "{'tokens_score': 1.4054651081081644, 'entities_score': 0.0, 'combined_score': 0.5621860432432658}\n",
    "\n",
    "query =  {'tokens': ['Times', 'Trump', 'travel'], 'entities': ['New York']}\n",
    "{'tokens_score': 1.4054651081081644, 'entities_score': 1.0, 'combined_score': 1.562186043243266}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the maximum score `max_score` among all the query splits is: <br>\n",
    "\n",
    "`1.562186043243266` <br>\n",
    "\n",
    "And, the corresponding query split is:<br>\n",
    "\n",
    "`{'tokens': ['Times', 'Trump', 'travel'], 'entities': ['New York']}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Format (Q1):\n",
    "Your output should be a tuple of the form:<br> \n",
    "`(max_score, {'tokens':[...], 'entities':[...]})`, where <br>\n",
    "* `max_score` corresponds to the maximum TF-IDF score among all the query splits based on $Q$ and $DoE$.\n",
    "* The query split corresponding to the `max_score`, i.e., a python dictionary containing the tokens and entities list corresponding to the query split `{'tokens':[...], 'entities':[...]}`.\n",
    "\n",
    "### Running Time (Q1):\n",
    "* On CSE machines, your implementation for $\\textbf{parsing and indexing}$ approx 500 documents of average length of 500 tokens $\\textbf{SHOULD NOT take more than 120 seconds}$. \n",
    "* Once all the documents are indexed, $\\textbf{the query spliting and score}$ computation $\\textbf{SHOULD NOT take more than 15 sec}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How we test implementation of Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'project_part1' from '/Users/wenke_yang/Desktop/6714 proj/Project_Part1/project_part1.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import importlib\n",
    "importlib.reload(project_part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'President Trump was on his way to new New York in New York City.',\n",
       " 2: 'New York Times mentioned an interesting story about Trump.',\n",
       " 3: 'I think it would be great if I can travel to New York this summer to see Trump.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = './Data/sample_documents.pickle'\n",
    "documents = pickle.load(open(fname,\"rb\"))\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step- 1. Construct the index...\n",
    "index = project_part1.InvertedIndex()\n",
    "\n",
    "index.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'President': {1: 1.0},\n",
       "             'way': {1: 1.0},\n",
       "             'new': {1: 1.0},\n",
       "             'New': {1: 1.5265890341390445, 2: 1.0, 3: 1.0},\n",
       "             'York': {1: 1.5265890341390445, 2: 1.0, 3: 1.0},\n",
       "             'City': {1: 1.0},\n",
       "             'Times': {2: 1.0},\n",
       "             'mentioned': {2: 1.0},\n",
       "             'interesting': {2: 1.0},\n",
       "             'story': {2: 1.0},\n",
       "             'think': {3: 1.0},\n",
       "             'great': {3: 1.0},\n",
       "             'travel': {3: 1.0},\n",
       "             'summer': {3: 1.0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.tf_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5c610b015b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m## 3. Compute the max-score...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_score_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/6714 proj/Project_Part1/project_part1.py\u001b[0m in \u001b[0;36mmax_score_query\u001b[0;34m(self, query_splits, doc_id)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mscore_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurr_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mscore_token\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midf_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mscorei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_entity\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscore_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "## Test cases\n",
    "Q = 'New York Times Trump travel'\n",
    "DoE = {'New York Times':0, 'New York':1,'New York City':2}\n",
    "doc_id = 3\n",
    "\n",
    "## 2. Split the query...\n",
    "query_splits = index.split_query(Q, DoE)\n",
    "\n",
    "## 3. Compute the max-score...\n",
    "result = index.max_score_query(query_splits, doc_id)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Submission and Feedback\n",
    "\n",
    "For project submission, you are required to submit the following files:\n",
    "\n",
    "1. Your implementation in a python file `project_part1.py`.\n",
    "\n",
    "2. A report `project_part1.pdf` You need to write a concise and simple report illustrating\n",
    "    - Implementation details of $Q1$.\n",
    "\n",
    "**Note:** Every student will be entitled to **15 Feedback Attempts** (use them wisely), we will use the last submission for final evaluation of **part-1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import spacy\n",
    "from math import log\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count term frequencies for entities and tokens in the documents       \n",
    "def _count_tf(documents):\n",
    "    # tf_count - key: term, value: {key: doc_id, value: # of this term in this doc_id}\n",
    "    entity_tf_count = defaultdict(lambda:defaultdict(int))\n",
    "    token_tf_count = defaultdict(lambda:defaultdict(int))\n",
    "\n",
    "    # documents: key - doc_id; value: document_text\n",
    "    for doc_id in documents.keys():\n",
    "        doc_text = nlp(documents[doc_id])\n",
    "\n",
    "        # decide to calculate entities first, because single word entities \n",
    "        #should not be counted as tokens, if tokens calculated first, extra deleting\n",
    "        #cost to token list\n",
    "        single_word_entities = defaultdict(list)\n",
    "\n",
    "        # count tf for entities\n",
    "        for ent in doc_text.ents:\n",
    "            entity_tf_count[ent.text][doc_id] += 1\n",
    "            \n",
    "            # if entity is a single word\n",
    "            if len(ent.text.split()) == 1:\n",
    "                single_word_entities[ent.text].append(ent.start_char)\n",
    "\n",
    "        # count tf for tokens       \n",
    "        for token in doc_text:\n",
    "            if not token.is_stop and not token.is_punct:\n",
    "                is_single_entity = False\n",
    "                # ent_iob - 3: begin entity, 2: outside, 1: inside\n",
    "                if (token.ent_iob == 1 or token.ent_iob == 3) \\\n",
    "                  and token.text in single_word_entities.keys() \\\n",
    "                  and token.idx in single_word_entities[token.text]:\n",
    "                    is_single_entity = True\n",
    "\n",
    "                if not is_single_entity:\n",
    "                    token_tf_count[token.text][doc_id] += 1\n",
    "                    \n",
    "    return entity_tf_count, token_tf_count\n",
    "\n",
    "# calculate tf and idf of tokens\n",
    "def _calc_tf_idf_token(token_tf_count, total_doc_no):\n",
    "    for token in token_tf_count.keys():\n",
    "        # calculate tf\n",
    "        for doc_id in token_tf_count[token]:\n",
    "            tf_token = token_tf_count[token][doc_id]\n",
    "            # calculate normalised token tf\n",
    "            tf_tokens[token][doc_id] = 1.0 + log(1.0 + log(tf_token))\n",
    "        \n",
    "        # calculate token idf\n",
    "        doc_contain_token = len(token_tf_count[token])\n",
    "        idf_tokens[token] = 1.0 + log(total_doc_no / (1.0 + doc_contain_token))\n",
    "    return\n",
    "    \n",
    "# calculate tf and idf of entities\n",
    "def _calc_tf_idf_entity(entity_tf_count, total_doc_no):\n",
    "    for ent in entity_tf_count:\n",
    "        # calculate tf\n",
    "        for doc_id in entity_tf_count[ent]:\n",
    "            tf_ent = entity_tf_count[ent][doc_id]\n",
    "\n",
    "            # calculate normalised entity tf\n",
    "            tf_entities[ent][doc_id] = 1.0 + log(tf_ent)\n",
    "        \n",
    "        # calculate entity idf\n",
    "        doc_contain_ent = len(entity_tf_count[ent])\n",
    "        idf_entities[ent] = 1.0 + log(total_doc_no / (1.0 + doc_contain_ent))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__._count_tf.<locals>.<lambda>()>,\n",
       "            {'Trump': defaultdict(int, {1: 1, 2: 1, 3: 1}),\n",
       "             'New York': defaultdict(int, {1: 1, 3: 1}),\n",
       "             'New York City': defaultdict(int, {1: 1}),\n",
       "             'New York Times': defaultdict(int, {2: 1}),\n",
       "             'this summer': defaultdict(int, {3: 1})})"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_tf_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_entities_with_index(query):\n",
    "    tokens = []\n",
    "    # entities - {key: entity, value: (start_index, end_index)}\n",
    "    # indices are useful for filtering \n",
    "    entities = defaultdict(tuple)\n",
    "    \n",
    "    for token in query:\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            tokens.append(token)\n",
    "            \n",
    "    for i in range(len(tokens)):\n",
    "        ti = tokens[i]\n",
    "        curr_ent = ti.text\n",
    "        if curr_ent in DoE.keys():\n",
    "            entities[curr_ent] = (ti.idx, ti.idx + len(curr_ent))\n",
    "        \n",
    "        for i, j in itertools.combinations(range(len(tokens) + 1), 2):\n",
    "            if i < j:\n",
    "                print(tokens[i:j])\n",
    "        \n",
    "        for j in range(i+1, len(tokens)):\n",
    "            tj = tokens[j]\n",
    "            curr_ent += ' ' + tj.text\n",
    "            if curr_ent in DoE.keys():\n",
    "                entities[curr_ent] = (ti.idx, tj.idx + len(curr_ent))\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([], ['B', 'Af', 'Af', 'B', 'C', 'D']),\n",
       " ([['Af', 'B']], ['B', 'Af', 'C', 'D']),\n",
       " ([['Af', 'B', 'D']], ['B', 'Af', 'C'])]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your implementation to split the query to tokens and entities...\n",
    "def split_query(Q, DoE):\n",
    "    # query Q: a string of words; DoE: key - entity, value - entity_id\n",
    "    query = nlp(Q)\n",
    "    entities, tokens, token_count = _get_entities(query, DoE)\n",
    "    subsets_ents = _get_subsets_ents(entities, token_count)\n",
    "    ents_and_tokens = _create_splits(subsets_ents, tokens)\n",
    "    return ents_and_tokens\n",
    "\n",
    "# enumerate all combinations of tokens in Q and filter by DoE\n",
    "# (2. step 1 and step 2)\n",
    "def _get_entities(query, DoE):\n",
    "    # tokenise the query\n",
    "    tokens = []\n",
    "    # token_count: {key: token, value: count} count no. of tokens in query\n",
    "    token_count = defaultdict(int)\n",
    "    \n",
    "    for token in query:\n",
    "        #if not token.is_stop and not token.is_punct:\n",
    "        tokens.append(token.text)\n",
    "        token_count[token.text] += 1\n",
    "            \n",
    "    # generate an entities: list of combinations of tokens         \n",
    "    entities = []\n",
    "    for ent_size in range(1, len(tokens) + 1):\n",
    "        for indicies in itertools.combinations(range(len(tokens)), ent_size):\n",
    "            ids = list(indicies)\n",
    "            ent = [tokens[i] for i in ids]\n",
    "            if ' '.join(ent) in DoE.keys():\n",
    "                entities.append((ent, list(indicies)))\n",
    "\n",
    "    return entities, tokens, token_count\n",
    "\n",
    "# enumerate all possible subsets of entities selected, filter by token count\n",
    "# (2. step 3)\n",
    "def _get_subsets_ents(entities, token_count):\n",
    "    subsets_ents = []\n",
    "    for i in range(len(entities) + 1):\n",
    "        for comb_subset_ents in itertools.combinations(entities, i):\n",
    "            subset_ents = list(comb_subset_ents)\n",
    "\n",
    "            if len(subset_ents) <= 1 or \\\n",
    "              (len(subset_ents) > 1 and not _exceed_token_count(subset_ents, token_count)):\n",
    "                subsets_ents.append(subset_ents)\n",
    "    \n",
    "    return subsets_ents\n",
    "\n",
    "# True if exceeded token count, else False\n",
    "def _exceed_token_count(subset_ents, token_count):\n",
    "    # sub_token_count: {key: token, value: count} \n",
    "    # count no. of tokens in this subset\n",
    "    sub_token_count = defaultdict(int)\n",
    "    total_indices = []\n",
    "    for ent, indices in subset_ents:\n",
    "        if len(set(total_indices).intersection(set(indices))) > 0:\n",
    "            return True\n",
    "        total_indices += indices\n",
    "        for token in ent:\n",
    "            sub_token_count[token] += 1\n",
    "            if sub_token_count[token] > token_count[token]:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# step 4: split according to each filtered entity subset\n",
    "def _create_splits(subsets_ents, tokens):\n",
    "    ents_and_tokens = []\n",
    "    for sub_ents in subsets_ents:\n",
    "        curr_tokens = tokens.copy()\n",
    "        curr_ents = []\n",
    "        all_indices = []\n",
    "        for ents, indices in sub_ents:\n",
    "            curr_ents += [ents]\n",
    "            all_indices += indices\n",
    "        \n",
    "        for i in all_indices:\n",
    "            curr_tokens[i] = ''\n",
    "        \n",
    "        curr_tokens = ' '.join(curr_tokens).split()\n",
    "        if (curr_ents, curr_tokens) not in ents_and_tokens:\n",
    "            ents_and_tokens.append((curr_ents, curr_tokens))\n",
    "        \n",
    "    return ents_and_tokens\n",
    "                \n",
    "         \n",
    "\n",
    "split_query('B Af Af B C D', {'Af B':0, 'Af B D':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your implementation to return the max score among all the query splits...\n",
    "def max_score_query(query_splits, doc_id):\n",
    "    ## Output should be a tuple (max_score, {'tokens': [...], 'entities': [...]})\n",
    "    max_score = -1\n",
    "    max_score_split = -1\n",
    "    for curr_ents, curr_tokens in query_splits:\n",
    "        score_entity = 0.0\n",
    "        for ent in curr_ents:\n",
    "            \n",
    "            full_ent = ' '.join(ent)\n",
    "            print(\"ent: \", full_ent)\n",
    "            score_entity += tf_entities[full_ent][doc_id] * idf_entities[full_ent]\n",
    "        \n",
    "        score_token = 0.0\n",
    "        for token in curr_tokens:\n",
    "            score_token += tf_tokens[token][doc_id] * idf_tokens[token]\n",
    "        \n",
    "        scorei = score_entity + 0.4 * score_token\n",
    "        if scorei > max_score:\n",
    "            max_score = scorei\n",
    "            max_score_split = (curr_ents, curr_tokens)\n",
    "        \n",
    "        print(\"tokens: \", curr_tokens)\n",
    "        print(\"entities: \", curr_ents)\n",
    "        print(\"token score: \", score_token)\n",
    "        print(\"entity score: \", score_entity)\n",
    "        print(\"combined score: \", scorei)\n",
    "        print()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'President Trump was on his way to new New York in New York City.',\n",
       " 2: 'New York Times mentioned an interesting story about Trump.',\n",
       " 3: 'I think it would be great if I can travel to New York this summer to see Trump.'}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = './Data/sample_documents.pickle'\n",
    "documents = pickle.load(open(fname,\"rb\"))\n",
    "## Test cases\n",
    "Q = 'New York Times Trump travel'\n",
    "DoE = {'New York Times':0, 'New York':1,'New York City':2}\n",
    "doc_id = 3\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You should use these variable to store the term frequencies for tokens and entities...\n",
    "# {key: token/entity, value: {key: doc_id, value: normalised term frequency(token/entity, doc_id)}}\n",
    "tf_tokens = defaultdict(lambda:defaultdict(float))\n",
    "tf_entities = defaultdict(lambda:defaultdict(float))\n",
    "\n",
    "## You should use these variable to store the inverse document frequencies for tokens and entities...\n",
    "# {key: token/entity, value: IDF(token/entity)}\n",
    "idf_tokens = defaultdict(float)\n",
    "idf_entities = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the english language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "total_doc_no = len(documents)\n",
    "entity_tf_count, token_tf_count = _count_tf(documents)\n",
    "\n",
    "_calc_tf_idf_token(token_tf_count, total_doc_no)\n",
    "_calc_tf_idf_entity(entity_tf_count, total_doc_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Times of India': defaultdict(float, {1: 1.0}),\n",
       "             'Donald Trump': defaultdict(float, {1: 1.0}),\n",
       "             'New York City': defaultdict(float, {1: 1.0}),\n",
       "             'UNGA': defaultdict(float, {1: 1.0}),\n",
       "             'The New York Times': defaultdict(float, {2: 1.0}),\n",
       "             'Trump': defaultdict(float, {2: 1.0, 3: 1.0}),\n",
       "             'New York': defaultdict(float, {3: 1.0}),\n",
       "             'this summer': defaultdict(float, {3: 1.0})})"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens:  ['The', 'New', 'New', 'York', 'City', 'Times', 'of', 'India']\n",
      "entities:  []\n",
      "token score:  5.947883998860986\n",
      "entity score:  0.0\n",
      "combined score:  2.3791535995443946\n",
      "\n",
      "ent:  New York City\n",
      "tokens:  ['The', 'New', 'Times', 'of', 'India']\n",
      "entities:  [['New', 'York', 'City']]\n",
      "token score:  3.117783035656384\n",
      "entity score:  1.4054651081081644\n",
      "combined score:  2.652578322370718\n",
      "\n",
      "ent:  Times of India\n",
      "tokens:  ['The', 'New', 'New', 'York', 'City']\n",
      "entities:  [['Times', 'of', 'India']]\n",
      "token score:  3.5424188907528213\n",
      "entity score:  1.4054651081081644\n",
      "combined score:  2.822432664409293\n",
      "\n",
      "ent:  The New York Times\n",
      "tokens:  ['New', 'City', 'of', 'India']\n",
      "entities:  [['The', 'New', 'York', 'Times']]\n",
      "token score:  3.5232481437645475\n",
      "entity score:  0.0\n",
      "combined score:  1.4092992575058192\n",
      "\n",
      "ent:  New York City\n",
      "ent:  Times of India\n",
      "tokens:  ['The', 'New']\n",
      "entities:  [['New', 'York', 'City'], ['Times', 'of', 'India']]\n",
      "token score:  0.7123179275482191\n",
      "entity score:  2.8109302162163288\n",
      "combined score:  3.0958573872356165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## 2. Split the query...\n",
    "query_splits = split_query(Q, DoE)\n",
    "max_score_query(query_splits, doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York Times Trump travel'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(('New', 'York', 'Times', 'Trump', 'travel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project_part1 as project_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'project_part1' from '/Users/wenke_yang/Desktop/6714 proj/Project_Part1/project_part1.py'>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(project_part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {1: 'According to Times of India, President Donald Trump was on his way to New York City after his address at UNGA.',\n",
    "             2: 'The New York Times mentioned an interesting story about Trump.',\n",
    "             3: 'I think it would be great if I can travel to New York this summer to see Trump.'}\n",
    "Q = 'The New New York City Times of India'\n",
    "DoE = {'Times of India':0, 'The New York Times':1,'New York City':2}\n",
    "doc_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = project_part1.InvertedIndex()\n",
    "index.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'According': {1: 1.0},\n",
       "             'Times': {1: 1.0, 2: 1.0},\n",
       "             'India': {1: 1.0},\n",
       "             'President': {1: 1.0},\n",
       "             'Donald': {1: 1.0},\n",
       "             'Trump': {1: 1.0},\n",
       "             'way': {1: 1.0},\n",
       "             'New': {1: 1.0, 2: 1.0, 3: 1.0},\n",
       "             'York': {1: 1.0, 2: 1.0, 3: 1.0},\n",
       "             'City': {1: 1.0},\n",
       "             'address': {1: 1.0},\n",
       "             'mentioned': {2: 1.0},\n",
       "             'interesting': {2: 1.0},\n",
       "             'story': {2: 1.0},\n",
       "             'think': {3: 1.0},\n",
       "             'great': {3: 1.0},\n",
       "             'travel': {3: 1.0},\n",
       "             'summer': {3: 1.0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.tf_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'Times of India': {1: 1.0},\n",
       "             'Donald Trump': {1: 1.0},\n",
       "             'New York City': {1: 1.0},\n",
       "             'UNGA': {1: 1.0},\n",
       "             'The New York Times': {2: 1.0},\n",
       "             'Trump': {2: 1.0, 3: 1.0},\n",
       "             'New York': {3: 1.0},\n",
       "             'this summer': {3: 1.0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.tf_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible query splits:\n",
      "\n",
      "{'tokens': ['The', 'New', 'New', 'York', 'City', 'Times', 'of', 'India'], 'entities': []}\n",
      "{'tokens': ['The', 'New', 'Times', 'of', 'India'], 'entities': ['New York City']}\n",
      "{'tokens': ['The', 'New', 'New', 'York', 'City'], 'entities': ['Times of India']}\n",
      "{'tokens': ['New', 'City', 'of', 'India'], 'entities': ['The New York Times']}\n",
      "{'tokens': ['The', 'New'], 'entities': ['New York City', 'Times of India']}\n"
     ]
    }
   ],
   "source": [
    "query_splits = index.split_query(Q, DoE)\n",
    "\n",
    "print('Possible query splits:\\n')\n",
    "for key,split in query_splits.items():\n",
    "    print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for each query split:\n",
      "\n",
      "query =  {'tokens': ['The', 'New', 'New', 'York', 'City', 'Times', 'of', 'India'], 'entities': []}\n",
      "{'tokens_score': 5.947883998860986, 'entities_score': 0.0, 'combined_score': 2.3791535995443946}\n",
      "\n",
      "query =  {'tokens': ['The', 'New', 'Times', 'of', 'India'], 'entities': ['New York City']}\n",
      "{'tokens_score': 3.117783035656384, 'entities_score': 1.4054651081081644, 'combined_score': 2.652578322370718}\n",
      "\n",
      "query =  {'tokens': ['The', 'New', 'New', 'York', 'City'], 'entities': ['Times of India']}\n",
      "{'tokens_score': 3.5424188907528213, 'entities_score': 1.4054651081081644, 'combined_score': 2.822432664409293}\n",
      "\n",
      "query =  {'tokens': ['New', 'City', 'of', 'India'], 'entities': ['The New York Times']}\n",
      "{'tokens_score': 3.5232481437645475, 'entities_score': 0.0, 'combined_score': 1.4092992575058192}\n",
      "\n",
      "query =  {'tokens': ['The', 'New'], 'entities': ['New York City', 'Times of India']}\n",
      "{'tokens_score': 0.7123179275482191, 'entities_score': 2.8109302162163288, 'combined_score': 3.0958573872356165}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 1\n",
    "\n",
    "print('Score for each query split:\\n')\n",
    "result = index.max_score_query(query_splits, doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum score:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.0958573872356165,\n",
       " {'tokens': ['The', 'New'], 'entities': ['New York City', 'Times of India']})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The maximum score:')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {1: 'According to Los Angeles Times, The Boston Globe will be experiencing another recession in 2020. However, The Boston Globe decales it a hoax.',\n",
    "             2: 'The Washington Post declines the shares of George Washington.',\n",
    "             3: 'According to Los Angeles Times, the UNSW COMP6714 students should be able to finish project part-1 now.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = project_part1.InvertedIndex()\n",
    "index.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'According': {1: 1.0, 3: 1.0},\n",
       "             'Los': {1: 1.0, 3: 1.0},\n",
       "             'Angeles': {1: 1.0, 3: 1.0},\n",
       "             'Times': {1: 1.0, 3: 1.0},\n",
       "             'Boston': {1: 1.5265890341390445},\n",
       "             'Globe': {1: 1.5265890341390445},\n",
       "             'experiencing': {1: 1.0},\n",
       "             'recession': {1: 1.0},\n",
       "             'decales': {1: 1.0},\n",
       "             'hoax': {1: 1.0},\n",
       "             'Washington': {2: 1.5265890341390445},\n",
       "             'Post': {2: 1.0},\n",
       "             'declines': {2: 1.0},\n",
       "             'shares': {2: 1.0},\n",
       "             'George': {2: 1.0},\n",
       "             'COMP6714': {3: 1.0},\n",
       "             'students': {3: 1.0},\n",
       "             'able': {3: 1.0},\n",
       "             'finish': {3: 1.0},\n",
       "             'project': {3: 1.0},\n",
       "             'part-1': {3: 1.0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.tf_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'Los Angeles Times': {1: 1.0, 3: 1.0},\n",
       "             'The Boston Globe': {1: 1.6931471805599454},\n",
       "             '2020': {1: 1.0},\n",
       "             'Washington Post': {2: 1.0},\n",
       "             'George Washington': {2: 1.0},\n",
       "             'UNSW': {3: 1.0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.tf_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible query splits:\n",
      "\n",
      "{'tokens': ['Los', 'The', 'Angeles', 'Boston', 'Times', 'Globe', 'Washington', 'Post'], 'entities': []}\n",
      "{'tokens': ['The', 'Boston', 'Globe', 'Washington', 'Post'], 'entities': ['Los Angeles Times']}\n",
      "{'tokens': ['Los', 'Angeles', 'Times', 'Washington', 'Post'], 'entities': ['The Boston Globe']}\n",
      "{'tokens': ['Los', 'Angeles', 'Boston', 'Times', 'Globe'], 'entities': ['The Washington Post']}\n",
      "{'tokens': ['Washington', 'Post'], 'entities': ['Los Angeles Times', 'The Boston Globe']}\n",
      "{'tokens': ['Boston', 'Globe'], 'entities': ['Los Angeles Times', 'The Washington Post']}\n"
     ]
    }
   ],
   "source": [
    "Q = 'Los The Angeles Boston Times Globe Washington Post'\n",
    "DoE = {'Los Angeles Times':0, 'The Boston Globe':1,'The Washington Post':2, 'Star Tribune':3}\n",
    "\n",
    "query_splits = index.split_query(Q, DoE)\n",
    "\n",
    "print('Possible query splits:\\n')\n",
    "for key,split in query_splits.items():\n",
    "    print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for each query split:\n",
      "\n",
      "query =  {'tokens': ['Los', 'The', 'Angeles', 'Boston', 'Times', 'Globe', 'Washington', 'Post'], 'entities': []}\n",
      "{'tokens_score': 7.29113524380594, 'entities_score': 0.0, 'combined_score': 2.916454097522376}\n",
      "\n",
      "query =  {'tokens': ['The', 'Boston', 'Globe', 'Washington', 'Post'], 'entities': ['Los Angeles Times']}\n",
      "{'tokens_score': 4.2911352438059405, 'entities_score': 1.0, 'combined_score': 2.7164540975223765}\n",
      "\n",
      "query =  {'tokens': ['Los', 'Angeles', 'Times', 'Washington', 'Post'], 'entities': ['The Boston Globe']}\n",
      "{'tokens_score': 3.0, 'entities_score': 2.3796592851687173, 'combined_score': 3.5796592851687175}\n",
      "\n",
      "query =  {'tokens': ['Los', 'Angeles', 'Boston', 'Times', 'Globe'], 'entities': ['The Washington Post']}\n",
      "{'tokens_score': 7.29113524380594, 'entities_score': 0.0, 'combined_score': 2.916454097522376}\n",
      "\n",
      "query =  {'tokens': ['Washington', 'Post'], 'entities': ['Los Angeles Times', 'The Boston Globe']}\n",
      "{'tokens_score': 0.0, 'entities_score': 3.3796592851687173, 'combined_score': 3.3796592851687173}\n",
      "\n",
      "query =  {'tokens': ['Boston', 'Globe'], 'entities': ['Los Angeles Times', 'The Washington Post']}\n",
      "{'tokens_score': 4.2911352438059405, 'entities_score': 1.0, 'combined_score': 2.7164540975223765}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 1\n",
    "\n",
    "print('Score for each query split:\\n')\n",
    "result = index.max_score_query(query_splits, doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum score:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.5796592851687175,\n",
       " {'tokens': ['Los', 'Angeles', 'Times', 'Washington', 'Post'],\n",
       "  'entities': ['The Boston Globe']})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The maximum score:\\n')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {0: \"Trump, Donald Trump, Donald Trump.\"}\n",
    "index = project_part1.InvertedIndex()\n",
    "index.index_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {'Trump': {0: 1.0}, 'Donald Trump': {0: 1.6931471805599454}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.tf_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'Donald': {0: 1.5265890341390445},\n",
       "             'Trump': {0: 1.5265890341390445}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.tf_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for each query split:\n",
      "\n",
      "query =  {'tokens': [], 'entities': []}\n",
      "{'tokens_score': 0.0, 'entities_score': 0.0, 'combined_score': 0.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Q = ''\n",
    "DoE = {'Trump':0,'Donald Trump':1, 'Donald Trump':2}\n",
    "\n",
    "query_splits = index.split_query(Q, DoE)\n",
    "doc_id = 0\n",
    "\n",
    "print('Score for each query split:\\n')\n",
    "result = index.max_score_query(query_splits, doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8, 9]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(10) if i>5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
